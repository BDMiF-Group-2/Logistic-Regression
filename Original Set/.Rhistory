# Print the confusion matrix
confusionMatrix(table(predictions, test_data$`Bankrupt?`))
# Generate predictions on the testing set
predictions <- predict(model, newdata = test_data , na.action = na.exclude , type = response)
# Generate predictions on the testing set
predictions <- predict(model, newdata = test_data , na.action = na.exclude , type = "response")
# Generate predictions on the testing set
predictions <- predict(model, newdata = test_data , na.action = na.exclude , type = "prob")
# Get the names of the columns in the training data
train_cols <- colnames(train_data)
# Subset the test data to only include those columns
test_data <- test_data[, train_cols]
library(janitor)
# Load the training data
train_data <- read_excel("rebalanced selected train.xlsx")
# Convert 'Bankrupt' to a factor with valid level names
train_data$`Bankrupt?` <- factor(train_data$`Bankrupt?`,
labels = make.names(levels(factor(train_data$`Bankrupt?`))))
# Load the test data
test_data <- read_excel("test.xlsx")
setwd("/Users/atharva/Desktop/16 April /Rebalanced With Feature Selection")
# Load the training data
train_data <- read_excel("rebalanced selected train.xlsx")
# Convert 'Bankrupt' to a factor with valid level names
train_data$`Bankrupt?` <- factor(train_data$`Bankrupt?`,
labels = make.names(levels(factor(train_data$`Bankrupt?`))))
# Load the test data
test_data <- read_excel("test.xlsx")
# Cleaning Names and test_data are your data frames
train_data <- janitor::clean_names(train_data)
test_data <- janitor::clean_names(test_data)
# Get the names of the columns in the training data
train_cols <- colnames(train_data)
# Subset the test data to only include those columns
test_data <- test_data[, train_cols]
# Load the training data
train_data <- read_excel.("rebalanced selected train.xlsx" , .name_repair = "universal")
# Load required libraries
library(caret)
library(glmnet)
library(readxl)
library(janitor)
# Load the training data
train_data <- read_excel.("rebalanced selected train.xlsx" , .name_repair = "universal")
# Load the training data
train_data <- read_excel("rebalanced selected train.xlsx" , .name_repair = "universal")
# Convert 'Bankrupt' to a factor with valid level names
train_data$`Bankrupt?` <- factor(train_data$`Bankrupt?`,
labels = make.names(levels(factor(train_data$`Bankrupt?`))))
# Convert 'Bankrupt' to a factor with valid level names
train_data$Bankrupt. <- factor(train_data$Bankrupt.,
labels = make.names(levels(factor(train_data$Bankrupt.))))
# Load the test data
test_data <- read_excel("test.xlsx",.name_repair = "universal")
# Get the names of the columns in the training data
train_cols <- colnames(train_data)
# Subset the test data to only include those columns
test_data <- test_data[, train_cols]
# Convert 'Bankrupt' to a factor with valid level names
test_data$bankrupt <- factor(test_data$bankrupt,
labels = make.names(levels(factor(test_data$bankrupt))))
# Convert 'Bankrupt' to a factor with valid level names
test_data$Bankrupt. <- factor(test_data$Bankrupt.,
labels = make.names(levels(factor(test_data$Bankrupt.))))
# Define the control method for training
ctrl <- trainControl(method = "cv", number = 5, classProbs = TRUE,
summaryFunction = twoClassSummary)
# Define a grid of hyperparameters to tune
# Here, we're tuning the cost parameter of the logistic regression model
grid <- expand.grid(.alpha = seq(0, 1, length.out = 10),  # alpha corresponds to the type of regularization (0 for L2, 1 for L1)
.lambda = seq(0.001, 1, length.out = 100))  # lambda corresponds to the strength of regularization
# Train the model with hyperparameter tuning
set.seed(123)
model <- train(`Bankrupt?` ~ . , data = train_data, method = "glmnet",
trControl = ctrl, metric = "ROC", tuneGrid = grid)
model <- train( Bankrupt. ~ . , data = train_data, method = "glmnet",
trControl = ctrl, metric = "ROC", tuneGrid = grid)
# Print the final model
print(model)
# Generate predictions on the testing set
predictions <- predict(model, newdata = test_data , na.action = na.exclude , type = "prob")
# Print the confusion matrix
confusionMatrix(table(predictions, test_data$`Bankrupt?`))
# Print the confusion matrix
confusionMatrix(table(predictions, test_data$Bankrupt.))
# Print the confusion matrix
confusionMatrix(table(predictions, test_data$Bankrupt.))
# Print the confusion matrix
confusionMatrix(table(predictions, test_data$Bankrupt.))
# Print the confusion matrix
confmatrix <- confusionMatrix(predictions, test_data$Bankrupt.)
predictions
# Generate predictions on the testing set
predictions <- predict(model, newdata = test_data , na.action = na.exclude )
# Generate predictions on the testing set
predictions <- predict(model, newdata = test_data , na.action = na.exclude ,)
# Print the confusion matrix
confusionMatrix(table(predictions, test_data$Bankrupt.))
probabs <- predict(model, newdata = test_data , type = "prob")
probabs
# Print the confusion matrix
confusionMatrix(table(predictions, test_data$Bankrupt.))
setwd("/Users/atharva/Desktop/16 April /Rebalanced Set ")
install.packages("e1071")
setwd("/Users/atharva/Desktop/16 April /Rebalanced Set ")
library(e1071)
# Load the training data
train_data <- read_excel("rebalanced selected train.xlsx" , .name_repair = "universal")
# Load required libraries
library(caret)
library(glmnet)
library(readxl)
library(janitor)
library(e1071)
# Load the training data
train_data <- read_excel("rebalanced selected train.xlsx" , .name_repair = "universal")
# Load the training data
train_data <- read_excel("rebalanced_set.xlsx" , .name_repair = "universal")
# Convert 'Bankrupt' to a factor with valid level names
train_data$Bankrupt. <- factor(train_data$Bankrupt.,
labels = make.names(levels(factor(train_data$Bankrupt.))))
# Load the test data
test_data <- read_excel("test.xlsx",.name_repair = "universal")
# Get the names of the columns in the training data
train_cols <- colnames(train_data)
# Subset the test data to only include those columns
test_data <- test_data[, train_cols]
# Convert 'Bankrupt' to a factor with valid level names
test_data$Bankrupt. <- factor(test_data$Bankrupt.,
labels = make.names(levels(factor(test_data$Bankrupt.))))
#Model
model <- naiveBayes(Bankrupt. ~ ., data = train_data)
# Print the final model
print(model)
# Generate predictions on the testing set
predictions <- predict(model, newdata = test_data , na.action = na.exclude )
# Print the confusion matrix
confusionMatrix(table(predictions, test_data$Bankrupt.))
# Define the tuning grid
tuneGrid <- expand.grid(fL = seq(0, 1, 0.1), usekernel = c(TRUE, FALSE))
# Train the model with the tuning grid
model <- train(Bankrupt. ~ ., data = train_data, method = "nb", tuneGrid = tuneGrid)
# Define the tuning grid
tuneGrid <- expand.grid(fL = seq(0, 1, 0.1), usekernel = c(TRUE, FALSE), adjust = seq(0, 1, 0.1))
# Train the model with the tuning grid
model <- train(Bankrupt. ~ ., data = train_data, method = "nb", tuneGrid = tuneGrid)
# Define the control parameters for the train function
ctrl <- trainControl(method = "cv", number = 10, summaryFunction = twoClassSummary, classProbs = TRUE)
# Train the model with the tuning grid
model <- train(Bankrupt. ~ ., data = train_data, method = "nb", tuneGrid = tuneGrid,trControl = ctrl,metric = "F1")
# Define the tuning grid
tuneGrid <- expand.grid(fL = seq(0, 1, 0.10), usekernel = c(TRUE, FALSE), adjust = seq(0, 1, 0.10))
# Train the model with the tuning grid
model <- train(Bankrupt. ~ ., data = train_data, method = "nb", tuneGrid = tuneGrid,trControl = ctrl,metric = "F1")
# Define the tuning grid
tuneGrid <- expand.grid(fL = seq(0, 1, 0.25), usekernel = c(TRUE, FALSE), adjust = seq(0, 1, 0.25))
# Define the control parameters for the train function
ctrl <- trainControl(method = "cv", number = 5, summaryFunction = twoClassSummary, classProbs = TRUE)
# Define the tuning grid
tuneGrid <- expand.grid(fL = seq(0, 1, 0.25), usekernel = c(TRUE, FALSE), adjust = seq(0, 1, 0.25))
# Train the model with the tuning grid
model <- train(Bankrupt. ~ ., data = train_data, method = "nb", tuneGrid = tuneGrid,trControl = ctrl,metric = "F1")
# Train the model with the tuning grid
model <- train(Bankrupt. ~ ., data = train_data, method = "nb" ,metric = "F1")
install.packages("naivebayes")
library(naivebayes)
# Define the control parameters for the train function
ctrl <- trainControl(method = "cv", number = 5, summaryFunction = twoClassSummary, classProbs = TRUE)
# Define the tuning grid
tuneGrid <- expand.grid(fL = seq(0, 1, 0.25), usekernel = c(TRUE, FALSE), adjust = seq(0, 1, 0.25))
# Train the model with the tuning grid
model <- train(target ~ ., data = train_data, method = "naive_bayes", trControl = ctrl, tuneGrid = tuneGrid, metric = "F1")
# Train the model with the tuning grid
model <- train(Bankrupt. ~ ., data = train_data, method = "naive_bayes", trControl = ctrl, tuneGrid = tuneGrid, metric = "F1")
# Define the tuning grid
tuneGrid <- expand.grid(laplace = seq(0, 1, 0.1), usekernel = c(TRUE, FALSE), adjust = seq(0, 1, 0.1))
# Train the model with the tuning grid
model <- train(Bankrupt. ~ ., data = train_data, method = "naive_bayes", trControl = ctrl, tuneGrid = tuneGrid, metric = "F1")
# Total number of iterations
total <- 242
# Create progress bar
pb <- txtProgressBar(min = 0, max = total, style = 3)
# Loop for model training
for(i in 1:total){
model <- train(Bankrupt. ~ ., data = train_data, method = "naive_bayes", trControl = ctrl, tuneGrid = tuneGrid, metric = "F1")
# Update progress bar
setTxtProgressBar(pb, i)
}
install.packages(c("mlr", "mlrMBO"))
library(mlr)
library(mlrMBO)
library(caret)
library(glmnet)
library(readxl)
library(janitor)
library(e1071)
library(naivebayes)
# Load the training data
train_data <- read_excel("rebalanced_set.xlsx" , .name_repair = "universal")
# Convert 'Bankrupt' to a factor with valid level names
train_data$Bankrupt. <- factor(train_data$Bankrupt.,
labels = make.names(levels(factor(train_data$Bankrupt.))))
# Load the test data
test_data <- read_excel("test.xlsx",.name_repair = "universal")
# Get the names of the columns in the training data
train_cols <- colnames(train_data)
# Subset the test data to only include those columns
test_data <- test_data[, train_cols]
# Convert 'Bankrupt' to a factor with valid level names
test_data$Bankrupt. <- factor(test_data$Bankrupt.,
labels = make.names(levels(factor(test_data$Bankrupt.))))
# Define the task
task <- makeClassifTask(data = train_data, target = "Bankrupt.")
colnames(train_data) <- make.names(colnames(train_data))
colnames(test_data) <- make.names(colnames(test_data))
# Define the task
task <- makeClassifTask(data = train_data, target = "Bankrupt.")
train_data <- make.names(colnames(train_data))
test_data <- make.names(colnames(test_data))
# Define the task
task <- makeClassifTask(data = train_data, target = "Bankrupt.")
colnames(train_data) <- make.names(colnames(train_data))
colnames(train_data) <- make.names(colnames(train_data))
train_data
colnames(train_data) <- make.names(colnames(train_data))
train_data
# Load the training data
train_data <- read_excel("rebalanced_set.xlsx" , .name_repair = "universal")
# Convert 'Bankrupt' to a factor with valid level names
train_data$Bankrupt. <- factor(train_data$Bankrupt.,
labels = make.names(levels(factor(train_data$Bankrupt.))))
# Load the test data
test_data <- read_excel("test.xlsx",.name_repair = "universal")
# Get the names of the columns in the training data
train_cols <- colnames(train_data)
# Subset the test data to only include those columns
test_data <- test_data[, train_cols]
train_data
# Convert 'Bankrupt' to a factor with valid level names
test_data$Bankrupt. <- factor(test_data$Bankrupt.,
labels = make.names(levels(factor(test_data$Bankrupt.))))
train_data
colnames(train_data) <- make.names(colnames(train_data))
train_data
# Define the task
task <- makeClassifTask(data = train_data, target = "Bankrupt.")
library(janitor)
train_data <- clean_names(train_data)
# Define the task
task <- makeClassifTask(data = train_data, target = "Bankrupt.")
# Define the task
task <- makeClassifTask(data = train_data, target = "bankrupt")
# Define the learner
learner <- makeLearner("classif.naiveBayes", predict.type = "prob")
# Define the parameter set
params <- makeParamSet(
makeDiscreteParam("laplace", values = seq(0, 1, 0.1)),
makeDiscreteParam("usekernel", values = c(TRUE, FALSE))
)
# Define the parameter set
params <- makeParamSet(
makeDiscreteParam("laplace", values = seq(0, 1, 0.1)),
makeDiscreteParam("usekernel", values = c(1, 0))
)
# Define the control strategy
ctrl <- makeMBOControl()
ctrl <- setMBOControlInfill(ctrl, opt.focussearch.points = 100, opt.restarts = 10, opt.maxit = 100)
ctrl <- makeMBOControl()
ctrl <- setMBOControlInfill(
control = ctrl,
crit = makeMBOInfillCritEI(),
opt.focussearch.points = 100,
opt.restarts = 10
)
# Run the optimization
res <- mbo(fun = learner, par.set = params, control = ctrl, show.info = TRUE)
# Define the objective function
obj.fun <- function(x) {
# Set the parameters for the learner
learner <- setHyperPars(learner, par.vals = x)
# Perform resampling
res <- resample(learner, task, resampling = cv5, measures = list(auc))
# Return the performance
return(res$aggr)
}
# Define the parameter set
params <- makeParamSet(
makeNumericParam("laplace", lower = 0, upper = 1),
makeLogicalParam("usekernel")
)
# Run the optimization
res <- mbo(fun = obj.fun, control = ctrl, show.info = TRUE)
install.packages("smoof")
install.packages("smoof")
install.packages("smoof")
library(smoof)
# Load the smoof package
library(smoof)
# Define the objective function
obj.fun <- makeSingleObjectiveFunction(
name = "Objective Function",
fn = function(x) {
# Set the parameters for the learner
learner <- setHyperPars(learner, par.vals = x)
# Perform resampling
res <- resample(learner, task, resampling = cv5, measures = list(auc))
# Return the performance
return(res$aggr)
},
par.set = params,
minimize = TRUE  # Set to FALSE if you want to maximize the function
)
# Run the optimization
res <- mbo(fun = obj.fun, control = ctrl, show.info = TRUE)
library(mlr)
library(mlrMBO)
library(caret)
library(glmnet)
library(readxl)
library(janitor)
library(e1071)
library(naivebayes)
library(janitor)
library(smoof)
# Load the training data
train_data <- read_excel("rebalanced_set.xlsx" , .name_repair = "universal")
# Convert 'Bankrupt' to a factor with valid level names
train_data$Bankrupt. <- factor(train_data$Bankrupt.,
labels = make.names(levels(factor(train_data$Bankrupt.))))
# Load the test data
test_data <- read_excel("test.xlsx",.name_repair = "universal")
# Get the names of the columns in the training data
train_cols <- colnames(train_data)
# Subset the test data to only include those columns
test_data <- test_data[, train_cols]
train_data
# Convert 'Bankrupt' to a factor with valid level names
test_data$Bankrupt. <- factor(test_data$Bankrupt.,
labels = make.names(levels(factor(test_data$Bankrupt.))))
train_data <- clean_names(train_data) t
train_data <- clean_names(train_data)
# Define the task
task <- makeClassifTask(data = train_data, target = "bankrupt")
# Define the learner
learner <- makeLearner("classif.naiveBayes", predict.type = "prob")
# Define the parameter set
params <- makeParamSet(
makeDiscreteParam("laplace", values = seq(0, 1, 0.1)),
makeDiscreteParam("usekernel", values = c(1, 0))
)
ctrl <- makeMBOControl()
ctrl <- setMBOControlInfill(
control = ctrl,
crit = makeMBOInfillCritEI(),
opt.focussearch.points = 100,
opt.restarts = 10
)
# Load the smoof package
library(smoof)
# Define the objective function
obj.fun <- makeSingleObjectiveFunction(
name = "Objective Function",
fn = function(x) {
# Set the parameters for the learner
learner <- setHyperPars(learner, par.vals = x)
# Perform resampling
res <- resample(learner, task, resampling = cv5, measures = list(auc))
# Return the performance
return(res$aggr)
},
par.set = params,
minimize = TRUE  # Set to FALSE if you want to maximize the function
)
# Run the optimization
res <- mbo(fun = obj.fun, control = ctrl, show.info = TRUE)
install.packages("randomForest")
library(randomForest)
# Run the optimization
res <- mbo(fun = obj.fun, control = ctrl, show.info = TRUE)
library(caret)
library(glmnet)
library(readxl)
library(janitor)
library(randomForest)
# Load the training data
train_data <- read_excel("rebalanced selected train.xlsx" , .name_repair = "universal")
# Convert 'Bankrupt' to a factor with valid level names
train_data$Bankrupt. <- factor(train_data$Bankrupt.,
labels = make.names(levels(factor(train_data$Bankrupt.))))
# Load the training data
train_data <- read_excel("rebalanced_set.xlsx" , .name_repair = "universal")
# Convert 'Bankrupt' to a factor with valid level names
train_data$Bankrupt. <- factor(train_data$Bankrupt.,
labels = make.names(levels(factor(train_data$Bankrupt.))))
# Load the test data
test_data <- read_excel("test.xlsx",.name_repair = "universal")
# Get the names of the columns in the training data
train_cols <- colnames(train_data)
# Subset the test data to only include those columns
test_data <- test_data[, train_cols]
# Convert 'Bankrupt' to a factor with valid level names
test_data$Bankrupt. <- factor(test_data$Bankrupt.,
labels = make.names(levels(factor(test_data$Bankrupt.))))
ctrl <- trainControl(method = "cv", number = 10)
tuneGrid <- expand.grid(.mtry = 1:ncol(train_data))
model <- train(target ~ ., data = train_data, method = "rf", trControl = ctrl, tuneGrid = tuneGrid)
model <- train(Bankrupt. ~ ., data = train_data, method = "rf", trControl = ctrl, tuneGrid = tuneGrid)
model <- train(Bankrupt. ~ ., data = train_data, method = "rf",)
model <- train(Bankrupt. ~ ., data = train_data, method = "glm")
# Generate predictions on the testing set
predictions <- predict(model, newdata = test_data , na.action = na.exclude )
probabs <- predict(model, newdata = test_data , type = "prob")
# Print the confusion matrix
confusionMatrix(table(predictions, test_data$Bankrupt.))
model <- train( Bankrupt. ~ . , data = train_data, method = "nb",
trControl = ctrl, metric = "ROC", tuneGrid = grid)
# Define the control method for training
ctrl <- trainControl(method = "cv", number = 5, classProbs = TRUE,
summaryFunction = twoClassSummary)
# Define a grid of hyperparameters to tune
# Here, we're tuning the cost parameter of the logistic regression model
grid <- expand.grid(.alpha = seq(0, 1, length.out = 10),  # alpha corresponds to the type of regularization (0 for L2, 1 for L1)
.lambda = seq(0.001, 1, length.out = 100))  # lambda corresponds to the strength of regularization
# Train the model with hyperparameter tuning
set.seed(123)
model <- train( Bankrupt. ~ . , data = train_data, method = "nb",
trControl = ctrl, metric = "ROC", tuneGrid = grid)
setwd("/Users/atharva/Desktop/16 April /Svm ")
setwd("/Users/atharva/Desktop/16 April /Original Set ")
# Load required libraries
library(glmnet)
library(readxl)
# Load the training data
train_data <- read_excel("rebalanced_set.xlsx")
# Load the training data
train_data <- read_excel("train.xlsx")
# Convert 'Bankrupt' to a factor with valid level names
train_data$`Bankrupt?` <- factor(train_data$`Bankrupt?`,
labels = make.names(levels(factor(train_data$`Bankrupt?`))))
# Convert 'Bankrupt' to a factor with valid level names
train_data$Bankrupt <- factor(train_data$Bankrupt,
labels = make.names(levels(factor(train_data$Bankrupt))))
# Load the test data
test_data <- read_excel("test.xlsx")
# Convert 'Bankrupt' to a factor with valid level names
test_data$`Bankrupt?` <- factor(test_data$`Bankrupt?`,
labels = make.names(levels(factor(test_data$`Bankrupt?`))))
# Define the control method for training
ctrl <- trainControl(method = "cv", number = 5, classProbs = TRUE,
summaryFunction = twoClassSummary)
# Define a grid of hyperparameters to tune
# Here, we're tuning the cost parameter of the logistic regression model
grid <- expand.grid(.alpha = seq(0, 1, length.out = 10),  # alpha corresponds to the type of regularization (0 for L2, 1 for L1)
.lambda = seq(0.001, 1, length.out = 100))  # lambda corresponds to the strength of regularization
model <- train(`Bankrupt?` ~ . , data = train_data, method = "glmnet",
trControl = ctrl, metric = "ROC", tuneGrid = grid)
model <- train( Bankrupt ~ . , data = train_data, method = "glmnet",
trControl = ctrl, metric = "ROC", tuneGrid = grid)
# Print the final model
print(model)
# Generate predictions on the testing set
predictions <- predict(model, newdata = test_data)
library(janitor)
train_data <- clean_names(train_data)
test_data <- clean_names(test_data)
# Generate predictions on the testing set
predictions <- predict(model, newdata = test_data)
# Load the test data
test_data <- read_excel("test.xlsx")
# Convert 'Bankrupt' to a factor with valid level names
test_data$`Bankrupt?` <- factor(test_data$`Bankrupt?`,
labels = make.names(levels(factor(test_data$`Bankrupt?`))))
# Define the control method for training
ctrl <- trainControl(method = "cv", number = 5, classProbs = TRUE,
summaryFunction = twoClassSummary)
# Define a grid of hyperparameters to tune
# Here, we're tuning the cost parameter of the logistic regression model
grid <- expand.grid(.alpha = seq(0, 1, length.out = 10),  # alpha corresponds to the type of regularization (0 for L2, 1 for L1)
.lambda = seq(0.001, 1, length.out = 100))  # lambda corresponds to the strength of regularization
# Train the model with hyperparameter tuning
set.seed(123)
model <- train( Bankrupt ~ . , data = train_data, method = "glmnet",
trControl = ctrl, metric = "ROC", tuneGrid = grid)
model <- train( Bankrupt ~ . , data = train_data, method = "glmnet",
trControl = ctrl, metric = "ROC", tuneGrid = grid)
model <- train( bankrupt ~ . , data = train_data, method = "glmnet",
trControl = ctrl, metric = "ROC", tuneGrid = grid)
# Print the final model
print(model)
# Generate predictions on the testing set
predictions <- predict(model, newdata = test_data)
# Load the test data
test_data <- read_excel("test.xlsx")
# Convert 'Bankrupt' to a factor with valid level names
test_data$`Bankrupt?` <- factor(test_data$`Bankrupt?`,
labels = make.names(levels(factor(test_data$`Bankrupt?`))))
# Convert 'Bankrupt' to a factor with valid level names
test_data$Bankrupt<- factor(test_data$Bankrupt,
labels = make.names(levels(factor(test_data$Bankrupt))))
# Generate predictions on the testing set
predictions <- predict(model, newdata = test_data)
train_data <- clean_names(train_data)
test_data <- clean_names(test_data)
# Generate predictions on the testing set
predictions <- predict(model, newdata = test_data)
confusionMatrix(table(predictions, test_data$`Bankrupt?`))
confusionMatrix(table(predictions, test_data$bankrupt))
library(MLmetrics)
install.packages("MLmetrics")
library(MLmetrics)
f1 <- F1_Score(test_data$bankrupt, predictions)
f1
